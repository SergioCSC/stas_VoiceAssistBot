1) How to fix all dependencies:  pip freeze > .\requirements_1.txt

2) 15.04.2023 19:16
openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details.

3) 16.04.2023
We pass FFMPEG_BINARY as the first argument to the subprocess.run() command, and then we pass
the rest of the ffmpeg command arguments as a command list.

Run command to convert audio
command = ["ffmpeg", "-i", "input.mp3", "output.wav"]
subprocess.run(command, check=True)

Running a command to extract audio from a video
command = ["ffmpeg", "-i", "input.mp4", "-vn", "-acodec", "copy", "output.m4a"]
subprocess.run(command, check=True)

4) 18.04.2023
async def send_echo(message: Message, bot: Bot):
    try:
        file_id = message.voice.file_id if message.voice else message.audio.file_id
        await message.reply(text=f"file info \n {file_id}")
        file = await bot.get_file(file_id)
        file_path = file.file_path
        await bot.download_file(file_path, "some_file.mp3")

async def send_echo(message: Message, bot: Bot): - implicitly, the framework passes the bot to the handler.
Thus it is possible use bot methods. Saved transferred audio files to disk

5) 19.04.2023
ADD second version func for download sound with read binaryIO and save to bytes in memory
async def process_download_audio(message: Message, bot: Bot):

Finish create func "convert_audio_to_mp3" and upgrade handler "process_audio_to_text"

To speed up the speed of audio playback in the FFmpeg command, you can use the "-filter:a" option
and specify "atempo" filter with speed factor ["-filter:a", f"atempo={speed}"], for example speed=1.5

Set a different bitrate, you can add the option "-b:a" (or "-ab") specifying the desired bitrate in kilobits per second
["-b:a", "192k"]

6) 20.04.2023
command = [FFMPEG_BINARY, "-i", "pipe:", "-b:a", "33k", "-filter:a", f"atempo={speed}", "pipe:"]
in the command parameters, we replaced path_input and path_output with "pipe:", which indicates input and output data
via stdin and stdout. We pass data to stdin via input and get the result via a BytesIO object to stdout.
result = output_data

Using subprocess.PIPE is a common approach when working with subprocesses, as it allows you to
capture the output of the subprocess in a way that is compatible with any platform or operating system.

By default, the run function returns the result of the command to the standard output stream.
If you want to get the result of the command, you need to add the stdout argument and set it to subprocess.PIPE:
In [9]: result = subprocess.run(['ls', '-ls'], stdout=subprocess.PIPE)
Now you can get the result of running the command like this:
In [10]: print(result.stdout)


In order to send a file, a special FSInputFile wrapper is used in aiogram for local files:
from aiogram.types.input_file import FSInputFile
document = FSInputFile('otchet.txt')
await bot.send_document(chatid, document)


Create func for text request to Open_AI:
def text_request_to_open_ai(text: str = "Hello!"):
    completion = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": f" 'Some specific param.': {text}"}])
    return completion.choices[0].message["content"]


Convert function now supports binary input and output

7) 21.04.2023
change func "transcribe_audio_to_text"
transcript = openai.Audio.transcribe_raw("whisper-1", file_bytes, "some_file.mp3")
If we want get to AI raw bytes

Create func for delete temp files
delete_temp_files(path: str = "temp")

Now func "convert_audio_to_mp3" work correct with "aac" format and return "bytes"

Create "temp" folder. Now all temp files to delete at the end

Add delete alert message after successful transcribe

Add path for ffmpeg in config.py


The first line ignores all files and folders in the project's root directory, except for the .gitignore file,
 so that this file is included in Git. The second line includes the "tmp" folder in the Git version control system.
  This way, if you create an empty "tmp" folder in your project's root directory, it will be included in Git.
/*
!/.gitignore
!/tmp/

8) 24.04.2023
moved func delete_files to other_services and upgrade func convert_audio_to_mp3

Function button_read_text_press now work correct and open big text message
file = callback.message.document
    file_bytes_io = await bot.download(file)
    text_str = file_bytes_io.read().decode('utf-8')

    split_text = other_services.split_text(text_str)
    for chunk_text in split_text:
        await callback.message.answer(text=chunk_text)

Add info about Bot functions

Moved function delete_temp to /services/other_services and
create function for split text for correct send message

import textwrap
def split_text(text: str, max_length: int = 4000):
    wrapped_text = textwrap.wrap(text=text, width=max_length, break_long_words=False)

add default param speed in func
try fix bug cycle request after press Inline Button on iphone

change func 'convert_audio_to_mp3' - add param 'speed' for convert., now func take bytes for bytes IO place


Add catch     "except openai.error.InvalidRequestError as e:
        if "Invalid file format" in str(e):"
Now Bot try decode file second time if open IA do not read file after decoding.

9) 25.04.2023
Added file type check to try to send AI directly and download size check
for bots limit save files is 20Mb, download - 50Mb

update function transcribe_audio_to_text, add new features

update lexicon

10) 26.04.2023

add first Inline button 'Send text to AI GPT 3.5'

change function text_request_to_open_ai, add error handling openai.error.APIConnectionError, add double resend message

Add callback_query handler for answer from first button to send text open ai

Now you can send a question to the GPT 3.5 chat after transcribing the voice at the touch of a button


11) 28.04.2023

Bot test without Open_AI library.
Step one - create from scratch the function of decoding audio to text.

curl.exe --request POST --url https://api.openai.com/v1/audio/transcriptions --header 'Authorization: Bearer sk-Token' --header 'Content-Type: multipart/form-data' --form file=@48655.mp3 --form model=whisper-1
So you can run in the command line win

If you need to pass the command as a single line, you can enclose parameters containing spaces in double quotes,
 arguments containing double quotes escape with a backslash:
curl_command = 'curl.exe --request POST' \
               ' --url https://api.openai.com/v1/audio/transcriptions' \
               ' --header "Authorization: Bearer sk-Token1"' \
               ' --header "Content-Type: multipart/form-data"' \
               ' --form "file=@48655.mp3"' \
               ' --form "model=whisper-1"' \
               ' --form "response_format=text"'

Here the Authorization and Content-Type parameters are enclosed in double quotes to ensure proper interpretation
parameter values containing spaces. The file parameter contains an @ symbol at the beginning to indicate the file name,
to be sent along with the request.

It's much easier to pass parameters as a list:

curl_command = ['curl.exe', '--request', 'POST',
                '--url', 'https://api.openai.com/v1/audio/transcriptions',
                '--header', 'Authorization: Bearer sk-Token1',
                '--header', 'Content-Type: multipart/form-data',
                '--form', 'file=@48655.mp3',
                '--form', 'model=whisper-1',
                '--form', 'response_format=text']


Для загрузки байтов файла через stdin, "file=@-;filename=q.mp3" - filename - обязательный параметр
curl_command = 'curl.exe --request POST' \
               ' --url https://api.openai.com/v1/audio/transcriptions' \
               ' --header "Authorization: Bearer sk-Token123"' \
               ' --header "Content-Type: multipart/form-data"' \
               ' --form "file=@-;filename=q.mp3"' \
               ' --form "model=whisper-1"' \
               ' --.form "response_format=text"'

curl_command = ['curl.exe', '--request', 'POST',
                    '--url', f'{TRANSCRIPTIONS_URL}',
                    '--header', f'Authorization: Bearer {OPENAI_API_KEY_FROM_HRY}',
                    '--header', 'Content-Type: multipart/form-data',
                    '--form', f'file=@-;filename=file_name.mp3',
                    '--form', f'model={model}']

For the transcribe_audio_to_text function, the --form parameter "response_format=text" had to be removed in order to receive a json file
with possible errors from open AI.

Added Dockerfile. Successfully built a working image based on python:3.10.11-alpine3.17

12) 29.04.2023
Some of the other possible values for the "message" field in the Open AI error object might include:
"Model 'model_name' not found": The specified model was not found in the system.
"Request timed out": The request timed out.
"API rate limit exceeded": You have exceeded the limit on the number of requests per unit of time.
"Internal server error": An internal server error has occurred.
"Invalid API key": The provided API key is invalid or does not exist.
"Invalid request format": The request was worded incorrectly or contains invalid parameters.
"Unauthorized API key": The provided API key does not have sufficient rights to make this request.
"Insufficient credits": You do not have enough credits to complete this request.
"Model 'model_name' is currently being fine-tuned and is not available for use": The specified model is currently being trained and is not available for use.
Update lexicon.py

Added a module for sending requests only with curl

Add working Dockerfile_curl_build for build bot with curl requests

Successfully built an image and tested it without the openAI library.
For Alpine and other libraries, you need to install curl - RUN apk add --no-cache curl

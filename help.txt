1) How to fix all dependencies:  pip freeze > .\requirements_1.txt

2) 15.04.2023 19:16
openai.error.RateLimitError: You exceeded your current quota, please check your plan and billing details.

3) 16.04.2023
We pass FFMPEG_BINARY as the first argument to the subprocess.run() command, and then we pass
the rest of the ffmpeg command arguments as a command list.

Run command to convert audio
command = ["ffmpeg", "-i", "input.mp3", "output.wav"]
subprocess.run(command, check=True)

Running a command to extract audio from a video
command = ["ffmpeg", "-i", "input.mp4", "-vn", "-acodec", "copy", "output.m4a"]
subprocess.run(command, check=True)

4) 18.04.2023
async def send_echo(message: Message, bot: Bot):
    try:
        file_id = message.voice.file_id if message.voice else message.audio.file_id
        await message.reply(text=f"file info \n {file_id}")
        file = await bot.get_file(file_id)
        file_path = file.file_path
        await bot.download_file(file_path, "some_file.mp3")

async def send_echo(message: Message, bot: Bot): - implicitly, the framework passes the bot to the handler.
Thus it is possible use bot methods. Saved transferred audio files to disk

5) 19.04.2023
ADD second version func for download sound with read binaryIO and save to bytes in memory
async def process_download_audio(message: Message, bot: Bot):

Finish create func "convert_audio_to_mp3" and upgrade handler "process_audio_to_text"

To speed up the speed of audio playback in the FFmpeg command, you can use the "-filter:a" option
and specify "atempo" filter with speed factor ["-filter:a", f"atempo={speed}"], for example speed=1.5

Set a different bitrate, you can add the option "-b:a" (or "-ab") specifying the desired bitrate in kilobits per second
["-b:a", "192k"]

6) 20.04.2023
command = [FFMPEG_BINARY, "-i", "pipe:", "-b:a", "33k", "-filter:a", f"atempo={speed}", "pipe:"]
in the command parameters, we replaced path_input and path_output with "pipe:", which indicates input and output data
via stdin and stdout. We pass data to stdin via input and get the result via a BytesIO object to stdout.
result = output_data

Using subprocess.PIPE is a common approach when working with subprocesses, as it allows you to
capture the output of the subprocess in a way that is compatible with any platform or operating system.

By default, the run function returns the result of the command to the standard output stream.
If you want to get the result of the command, you need to add the stdout argument and set it to subprocess.PIPE:
In [9]: result = subprocess.run(['ls', '-ls'], stdout=subprocess.PIPE)
Now you can get the result of running the command like this:
In [10]: print(result.stdout)


In order to send a file, a special FSInputFile wrapper is used in aiogram for local files:
from aiogram.types.input_file import FSInputFile
document = FSInputFile('otchet.txt')
await bot.send_document(chatid, document)


Create func for text request to Open_AI:
def text_request_to_open_ai(text: str = "Hello!"):
    completion = openai.ChatCompletion.create(
        model="gpt-3.5-turbo",
        messages=[{"role": "user", "content": f" 'Some specific param.': {text}"}])
    return completion.choices[0].message["content"]


Convert function now supports binary input and output

7) 21.04.2023
change func "transcribe_audio_to_text"
transcript = openai.Audio.transcribe_raw("whisper-1", file_bytes, "some_file.mp3")
If we want get to AI raw bytes

Create func for delete temp files
delete_temp_files(path: str = "temp")

Now func "convert_audio_to_mp3" work correct with "aac" format and return "bytes"

Create "temp" folder. Now all temp files to delete at the end

Add delete alert message after successful transcribe

Add path for ffmpeg in config.py


The first line ignores all files and folders in the project's root directory, except for the .gitignore file,
 so that this file is included in Git. The second line includes the "tmp" folder in the Git version control system.
  This way, if you create an empty "tmp" folder in your project's root directory, it will be included in Git.
/*
!/.gitignore
!/tmp/

8) 24.04.2023
moved func delete_files to other_services and upgrade func convert_audio_to_mp3

Function button_read_text_press now work correct and open big text message
file = callback.message.document
    file_bytes_io = await bot.download(file)
    text_str = file_bytes_io.read().decode('utf-8')

    split_text = other_services.split_text(text_str)
    for chunk_text in split_text:
        await callback.message.answer(text=chunk_text)

Add info about Bot functions

Moved function delete_temp to /services/other_services and
create function for split text for correct send message

import textwrap
def split_text(text: str, max_length: int = 4000):
    wrapped_text = textwrap.wrap(text=text, width=max_length, break_long_words=False)

add default param speed in func
try fix bug cycle request after press Inline Button on iphone

change func 'convert_audio_to_mp3' - add param 'speed' for convert., now func take bytes for bytes IO place


Add catch     "except openai.error.InvalidRequestError as e:
        if "Invalid file format" in str(e):"
Now Bot try decode file second time if open IA do not read file after decoding.

9) 25.04.2023
Added file type check to try to send AI directly and download size check
for bots limit save files is 20Mb, download - 50Mb

update function transcribe_audio_to_text, add new features

update lexicon

10) 26.04.2023

add first Inline button 'Send text to AI GPT 3.5'

change function text_request_to_open_ai, add error handling openai.error.APIConnectionError, add double resend message

Add callback_query handler for answer from first button to send text open ai

Now you can send a question to the GPT 3.5 chat after transcribing the voice at the touch of a button


11) 28.04.2023

Тест бота без библиотеки Open_AI.
Шаг первый - создаем с нуля функцию декодирования аудио в текст.

curl.exe --request POST --url https://api.openai.com/v1/audio/transcriptions --header 'Authorization: Bearer sk-Token' --header 'Content-Type: multipart/form-data' --form file=@48655.mp3 --form model=whisper-1
Так можно запустить в командной строке win

Если вам нужно передать команду в виде одной строки, вы можете заключить параметры, содержащие пробелы, в двойные кавычки, аргументы, содержащие двойные кавычки, экранировать обратным слешем:

curl_command = 'curl.exe --request POST' \
               ' --url https://api.openai.com/v1/audio/transcriptions' \
               ' --header "Authorization: Bearer sk-Token1"' \
               ' --header "Content-Type: multipart/form-data"' \
               ' --form "file=@48655.mp3"' \
               ' --form "model=whisper-1"' \
               ' --form "response_format=text"'

Здесь параметры Authorization и Content-Type заключены в двойные кавычки, чтобы обеспечить правильную интерпретацию
значений параметров, содержащих пробелы. Параметр file содержит символ @ в начале, чтобы указать имя файла,
который необходимо отправить вместе с запросом.

Намного проще передать параметры в виде списка:

curl_command = ['curl.exe', '--request', 'POST',
                '--url', 'https://api.openai.com/v1/audio/transcriptions',
                '--header', 'Authorization: Bearer sk-Token1',
                '--header', 'Content-Type: multipart/form-data',
                '--form', 'file=@48655.mp3',
                '--form', 'model=whisper-1',
                '--form', 'response_format=text']


Для загрузки байтов файла через stdin, "file=@-;filename=q.mp3" - filename - обязательный параметр
curl_command = 'curl.exe --request POST' \
               ' --url https://api.openai.com/v1/audio/transcriptions' \
               ' --header "Authorization: Bearer sk-Token123"' \
               ' --header "Content-Type: multipart/form-data"' \
               ' --form "file=@-;filename=q.mp3"' \
               ' --form "model=whisper-1"' \
               ' --form "response_format=text"'

curl_command = ['curl.exe', '--request', 'POST',
                    '--url', f'{TRANSCRIPTIONS_URL}',
                    '--header', f'Authorization: Bearer {OPENAI_API_KEY_FROM_HRY}',
                    '--header', 'Content-Type: multipart/form-data',
                    '--form', f'file=@-;filename=file_name.mp3',
                    '--form', f'model={model}']

Для функции transcribe_audio_to_text параметр --form "response_format=text" пришлось убрать, чтобы получать json файл
с возможными ошибками от open AI.

Добавил Dockerfile. Успешно собрал работоспособный образ на базе python:3.10.11-alpine3.17
